{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os, requests\n",
    "from time import process_time as timer\n",
    "from PFL_memory_supplements import *\n",
    "import gc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Python for Lunch (PFL) - Performance Sessions - C-bindings \n",
    "\n",
    "# _A Python on Steroids_ \n",
    "\n",
    "Last week, we looked at memory consumption and speeding-up I/O-bound programs in Python. This week, we focus on the complementary case: speeding-up compute-bound programs in Python! (i.e. the actual **fun** stuff!) \n",
    "\n",
    "## Motivation\n",
    "\n",
    "In PFL 19, we looked at time measurements. At the closure, we measure *compute time*, *I/O time* and the *compute-to-I/O ratio*.\n",
    "We learned that the latter ratio indicates what we need to prioritize when increasing the performance of a program, and also said that compute-enhancing techniques (i.e. *Python-on-Steriods*) only makes sense if that ratio is *considerably higher than 1*.\n",
    "\n",
    "Measuring those timings in actual, large Python programs is quite difficult due to the high conceptual level of Python.\n",
    "Realistic programs in Physics are often I/O-bound (i.e. ratio less than 1), cause data are stored in huge files and data copies are needed to hold previous-iteration values.\n",
    "Some codes (e.g. CESM or CMEMS themselves) are based on finite-difference *ordinary differential equations (ODE's)*, which require only limited external data input.\n",
    "Those codes are usually *compute-bound*, meaning that the performance bottleneck is the amount of *floating-point operations per second (FLOPS)* that are performed. It is also the case where using Python (as a programming language) can be _**the**_ major limitation.\n",
    "Today, we look into ways to speed up compute-bound programs in Python, continuing the theme of last week, where we looked at speeding-up I/O-bound programs.\n",
    "\n",
    "### Programming Language Speed & Python\n",
    "\n",
    "Not all programming languages are the same. Every programming language has its preferred application scenarios, its intended use and its advantages.\n",
    "For some (or: most) of you, *Python* is the only programming language you know, whereas the *older generation* can still remember coding in *FORTRAN*.\n",
    "Those programming languages are very prominent in Physics. When comparing the two, one can overall observe that FORTRAN programs are very, very fast. The drawback of FORTRAN is that its very laborious to program, and very error-prone.\n",
    "Those are the drawbacks Python was uniquely designed to address and remedy - though the easy of development came at the expense of computation speed.\n",
    "\n",
    "One point here: if we talk about *Python* as a language, we talk about *plain Python*, not: *NumPy*, *SciPy*, *Scikits*. Those difference we will discuss and experience within this PFL session.\n",
    "Actuual, plain Python consists of the following instructions:\n",
    "\n",
    "- for-loops (i.e. `for ... in range(start, stop)`)\n",
    "- while-loops\n",
    "- list-comprehensions (Python-exclusive)\n",
    "- for-each loops (i.e. `for obj in list`)\n",
    "- lambda-expressions\n",
    "\n",
    "In the *Computer Sciences (CS)*, the prevalent modern programming language that are most commonly used are:\n",
    "\n",
    "- Java (e.g. business-logic programs)\n",
    "- JavaScript (i.e. web-apps)\n",
    "- C++ (anything but web)\n",
    "- C (i.e. close-to-chip programming)\n",
    "- C#\n",
    "- Python (getting more promiment due to simplicity and AI/ML/DeepLearning-stuff)\n",
    "\n",
    "In essence, all *high-level languages (HLL's)* - those are: all languages beyond *Assembler*, *C*, *C++/Objective C* and *FORTRAN* - are rooted in **C/C++**. \n",
    "That is because those 2 languages translate (via a *compiler*) directly into byte-code that can be executed by the hardware (i.e. the CPU).\n",
    "This translation step from an easy-to-use, type-less, error-resilient, interpreter-bound HLL into C-code instructions is a *speed malus* (i.e. performance cost) you 'pay' with each function call.\n",
    "\n",
    "So: using Python costs us speed in computation, and this cost can be measured in the runtime of programs.\n",
    "One intensely-discussed question in this context is: *How high is that cost ? How much slower is Python, compared to C or C++ ?*\n",
    "To quantify that, a good starting point are programming language benchmarks & speed comparisons, such as:\n",
    "\n",
    "- overview: [the computer language benchmark game](https://benchmarksgame-team.pages.debian.net/benchmarksgame/)\n",
    "- [Python3 vs. C (on Linux) benchmarks](https://benchmarksgame-team.pages.debian.net/benchmarksgame/fastest/python3-gcc.html)\n",
    " \n",
    "What we see in those comparisons is that Python3's speed (as runtime) compared to C is a between 2:1 (Python's runtime is 2x as much as 1 C-runtime) for toy-computations, \n",
    "40:1 for frequently occuring compute problems (e.g. sorting) and >100:1 for complex problems (e.g. nBody). Thus, if we want to get **real speed* of our *actual* calculations, we should not do them inside Python.\n",
    "The logical follow-up question(s):\n",
    " \n",
    "- **What shall we do ?**\n",
    "- **Is there the possibility to keep using _Python_, but then 'out-source' the calculations to C or C++ ?**\n",
    "\n",
    "Today, those are the questions we urge to answer!"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Case Study - k-Nearest Neighbour on Particles\n",
    "\n",
    "In order to answer this question, we design a suitable case study again. In the case study of today, we re-use the particle advection on flow-fields that we developed in PFL 19.\n",
    "In this case study, we tracer particles move on a defined flow field (i.e. *advection*) over a set time frame (or: number of iterations).\n",
    "Today, we expand the calculation by determining the *k-nearest neighbouring (kNN)* particles for *each particle* at *each iteration step*.\n",
    "This neighbourhood computation is well-known in CS as a very compute-intensive operation, as it involves and _N * (N over N)_ distance calculation, followed\n",
    "by a _k * N log N_ ordering of those distances. It is a typical computation bottleneck.\n",
    "\n",
    "Further, it's a good example because:\n",
    "- there is not just *1 solution* to the problem, and it can be solved in many ways\n",
    "- it's computational complexity is well-known and well-bound\n",
    "- thus, speed difference actually come from implementation differences\n",
    "- if follows the 'simple to code, hard to master' paradigm\n",
    "- it only consists of for-loops, branch conditionals etc., and thus can be done just using the inherent programming language instructions\n",
    "\n",
    "Let's start and prepare and run this example first using exclusively Python-code."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "text": [
      "/home/ckehl/.local/lib/python3.6/site-packages/scipy/io/netcdf.py:314: RuntimeWarning: Cannot close a netcdf_file opened with mmap=True, when netcdf_variables or arrays referring to its data still exist. All data arrays obtained from such files refer directly to data on disk, and must be copied before the file can be cleanly closed. (See netcdf_file docstring for more information on mmap.)\n",
      "  ), category=RuntimeWarning)\n"
     ],
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": [
      "==== running the simulation with competing procs ====\n",
      "Processing at  0.1351351 percent ...\n",
      "Processing at 10.0000000 percent ...\n",
      "Processing at 20.0000000 percent ...\n",
      "Processing at 30.0000000 percent ...\n",
      "Processing at 40.0000000 percent ...\n",
      "Processing at 50.0000000 percent ...\n",
      "Processing at 60.0000000 percent ...\n",
      "Processing at 70.0000000 percent ...\n",
      "Processing at 80.0000000 percent ...\n",
      "Processing at 90.0000000 percent ...\n",
      "Processing at 100.0000000 percent ...\n",
      "Total processing time (high-res timer): 631.2895284 sec.\n",
      "Average processing kernel time (high-res timer):  0.8530562 sec.\n",
      "Compute percentage of runtime:                       99.9952297\n",
      "Compute percentage simulation time (Advection-only): 92.7623401\n",
      "I/O percentage of simulation time:                    7.2376599\n",
      "------------------------------------------------------------------\n",
      "Ratio Compute time vs. I/O time:              1788.8475113\n",
      "Ratio Advection time vs. I/O-simulation time: 12.8187770\n",
      "------------------------------------------------------------------\n",
      "Percentage of Advection on Compute time:             0.7764\n",
      "Percentage of Nearest-Neighbour on Compute time:    99.2236\n"
     ],
     "output_type": "stream"
    },
    {
     "data": {
      "text/plain": "5"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 2
    }
   ],
   "source": [
    "def kNN_particles_PythonOnly(simulation, k=5):\n",
    "    N = len(simulation)\n",
    "    r = (b-a)\n",
    "    r = math.sqrt(np.dot(r,r))\n",
    "    distance_matrix = np.ones((N,N), dtype=np.float64) * r\n",
    "    for i in range(0, N):\n",
    "        for j in range (i, N):\n",
    "            if i==j:\n",
    "                distance_matrix[i,j] = .0\n",
    "                continue\n",
    "            # dv = simulation[i].pt[0:1]-simulation[j].pt[0:1]\n",
    "            # dv_len = dv[0]*dv[0]+dv[1]*dv[1]\n",
    "            dx = simulation[i].pt[0]-simulation[j].pt[0]\n",
    "            dy = simulation[i].pt[1]-simulation[j].pt[1]\n",
    "            dv_len_sqr = dx*dx+dy*dy\n",
    "            distance_matrix[i, j] = dv_len_sqr\n",
    "            distance_matrix[j, i] = dv_len_sqr\n",
    "    \n",
    "    kNN_indices = np.ones((N,k), dtype=np.uint32) * -1\n",
    "    kNN_distances = np.ones((N,k), dtype=np.float64) * r\n",
    "    for i in range(0, N):\n",
    "        for j in range (0, N):\n",
    "            if i==j:\n",
    "                continue\n",
    "            m = 0\n",
    "            while (m<k) and ((kNN_indices[i, m] < 0) or (kNN_distances[i, m] <= distance_matrix[i, j])):\n",
    "                m += 1\n",
    "            if not m<k:\n",
    "                continue\n",
    "            l = k-1\n",
    "            while l>m:\n",
    "                kNN_indices[i, l] = kNN_indices[i, l-1]\n",
    "                kNN_distances[i, l] = kNN_distances[i, l-1]\n",
    "            kNN_indices[i, m] = j\n",
    "            kNN_distances[i, m] = distance_matrix[i, j]\n",
    "    return kNN_indices, kNN_distances\n",
    "            \n",
    "\n",
    "\n",
    "if not os.path.exists('perlin.nc'):\n",
    "    data_url = \"https://surfdrive.surf.nl/files/index.php/s/T7QyLbGjaGMdnVD/download\"\n",
    "    requests.get(data_url)\n",
    "# ==== Load flow-field data - measure the time ==== #\n",
    "s_io_file_time = timer()\n",
    "f = netcdf.netcdf_file('perlin.nc', 'r')\n",
    "ftimes = f.variables['time'].data\n",
    "fX = f.variables['lon'].data\n",
    "fY = f.variables['lat'].data\n",
    "fU = f.variables['u'].data\n",
    "fV = f.variables['v'].data\n",
    "f.close()\n",
    "e_io_file_time = timer()\n",
    "io_file_time = e_io_file_time-s_io_file_time\n",
    "\n",
    "a = np.array([fX[0], fY[0]])\n",
    "b = np.array([fX[-1], fY[-1]])\n",
    "t_0_N = np.array([ftimes[0], ftimes[-1]])\n",
    "T = t_0_N[1]-t_0_N[0]\n",
    "dt = 12.0 * 60.0 * 60.0\n",
    "sim_steps = int(math.floor(T/dt))\n",
    "total_compute_times = []\n",
    "advect_compute_time = []\n",
    "kNN_compute_time = []\n",
    "\n",
    "sim = Simulation_Benchmark(fX, fY, ftimes, fU, fV)\n",
    "for i in range(0, 512):\n",
    "    pt = (b - a) * np.random.random_sample(2)  + a\n",
    "    sim.add_particle(pt[0], pt[1])\n",
    "\n",
    "# total_compute_times.clear()\n",
    "print(\"==== running the simulation with competing procs ====\")\n",
    "stime_sim = timer()\n",
    "prev_int_proc = -1\n",
    "cur_int_proc = 0\n",
    "while sim.sim_time < sim.sim_end_time:\n",
    "    stime_compute_advect = timer()\n",
    "    sim.advect_once(dt)\n",
    "    etime_compute_advect = timer()\n",
    "    stime_kNN = timer()\n",
    "    kNN_particles_PythonOnly(sim, k=5)\n",
    "    etime_kNN = timer()\n",
    "    advectTime = etime_compute_advect-stime_compute_advect\n",
    "    knnTime = etime_kNN-stime_kNN\n",
    "    advect_compute_time.append(advectTime)\n",
    "    kNN_compute_time.append(knnTime)\n",
    "    total_compute_times.append(advectTime+knnTime)\n",
    "    proc_done = (sim.sim_time / sim.sim_end_time)*100\n",
    "    cur_int_proc = int(math.floor(proc_done/10))\n",
    "    if prev_int_proc != cur_int_proc:\n",
    "        print(\"Processing at {:10.7f} percent ...\".format(proc_done))\n",
    "    prev_int_proc = cur_int_proc\n",
    "\n",
    "etime_sim = timer()\n",
    "sim_total_time = etime_sim-stime_sim\n",
    "print(\"Total processing time (high-res timer): {:10.7f} sec.\".format(sim_total_time))\n",
    "avg_ptimer_hr = np.array(total_compute_times).mean()\n",
    "print(\"Average processing kernel time (high-res timer): {:10.7f} sec.\".format(avg_ptimer_hr))\n",
    "\n",
    "total_compute_time = np.array(total_compute_times).sum()\n",
    "total_advect_time = np.array(advect_compute_time).sum()\n",
    "total_knn_time = np.array(kNN_compute_time).sum()\n",
    "\n",
    "compute_to_total_ratio = total_compute_time / (sim_total_time+io_file_time)\n",
    "compute_to_iototal = total_compute_time / (sim.io_mem_time+io_file_time)\n",
    "io_to_sim_ratio = sim.io_mem_time / (sim.compute_time+sim.io_mem_time)\n",
    "advect_to_sim = sim.compute_time / (sim.compute_time+sim.io_mem_time)\n",
    "advect_to_iosim = sim.compute_time / sim.io_mem_time+io_file_time\n",
    "advect_compute_percentage = (total_advect_time / total_compute_time) * 100.0\n",
    "knn_compute_percentage = (total_knn_time / total_compute_time) * 100.0\n",
    "\n",
    "total_compute_time_PythonOnly = total_compute_time\n",
    "total_advect_time_PythonOnly = total_advect_time\n",
    "total_knn_time_PythonOnly = total_knn_time\n",
    "\n",
    "print(\"Compute percentage of runtime:                       {:10.7f}\".format(compute_to_total_ratio*100.0))\n",
    "print(\"Compute percentage simulation time (Advection-only): {:10.7f}\".format(advect_to_sim*100.0))\n",
    "print(\"I/O percentage of simulation time:                   {:10.7f}\".format(io_to_sim_ratio*100.0))\n",
    "print(\"------------------------------------------------------------------\")\n",
    "print(\"Ratio Compute time vs. I/O time:              {:10.7f}\".format(compute_to_iototal))\n",
    "print(\"Ratio Advection time vs. I/O-simulation time: {:10.7f}\".format(advect_to_iosim))\n",
    "print(\"------------------------------------------------------------------\")\n",
    "print(\"Percentage of Advection on Compute time:         {:10.4f}\".format(advect_compute_percentage))\n",
    "print(\"Percentage of Nearest-Neighbour on Compute time: {:10.4f}\".format(knn_compute_percentage))\n",
    "del sim\n",
    "del ftimes\n",
    "del fX\n",
    "del fY\n",
    "del fU\n",
    "del fV\n",
    "del total_compute_times\n",
    "del advect_compute_time\n",
    "del kNN_compute_time\n",
    "gc.collect()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "From this benchmark measurement, we observe the following:\n",
    "- our advect-vs-io ratio is >10: our actual particle simulation is already compute-bound\n",
    "- our total compute-vs-io ratio is >100: including the kNN search results in a highly compute-bound process overall\n",
    "- more than 75 percent of the advection is pure calculation, hence the advection is dominated by FLOP's\n",
    "- 99 percent of the computation time is spent in nearest-neighbour search, which meanns that this would be the one function we need to optimize\n",
    "\n",
    "Overall, as intended, this case is a very good optimisation example to follow up on. So, now: what can we do to improve the performance ? How can we speed up the calculation ?"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Optimisation 1: Use *NumPy* in own kNN search\n",
    "\n",
    "In this next step, we use vectorisation and dense memory layout by arranging out particles in tightly-packed memory blocks. This change means we can use optimize hardware technologies, such as *caches*.\n",
    "How can we do that ? In Python, this is quite simple by glue all operations (as best as possible) of our kNN-function into matrix-operations, that are executed in **NumPy**."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "text": [
      "/home/ckehl/.local/lib/python3.6/site-packages/scipy/io/netcdf.py:314: RuntimeWarning: Cannot close a netcdf_file opened with mmap=True, when netcdf_variables or arrays referring to its data still exist. All data arrays obtained from such files refer directly to data on disk, and must be copied before the file can be cleanly closed. (See netcdf_file docstring for more information on mmap.)\n",
      "  ), category=RuntimeWarning)\n"
     ],
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": [
      "==== running the simulation with competing procs ====\n",
      "Processing at  0.1351351 percent ...\n",
      "Processing at 10.0000000 percent ...\n",
      "Processing at 20.0000000 percent ...\n",
      "Processing at 30.0000000 percent ...\n",
      "Processing at 40.0000000 percent ...\n",
      "Processing at 50.0000000 percent ...\n",
      "Processing at 60.0000000 percent ...\n",
      "Processing at 70.0000000 percent ...\n",
      "Processing at 80.0000000 percent ...\n",
      "Processing at 90.0000000 percent ...\n",
      "Processing at 100.0000000 percent ...\n",
      "Total processing time (high-res timer): 21.9434084 sec.\n",
      "Average processing kernel time (high-res timer):  0.0296098 sec.\n",
      "Compute percentage of runtime:                       99.8504835\n",
      "Compute percentage simulation time (Advection-only): 93.1629152\n",
      "I/O percentage of simulation time:                    6.8370848\n",
      "------------------------------------------------------------------\n",
      "Ratio Compute time vs. I/O time:              35.6252213\n",
      "Ratio Advection time vs. I/O-simulation time: 13.6267686\n",
      "------------------------------------------------------------------\n",
      "Percentage of Advection on Compute time:            41.5248\n",
      "Percentage of Nearest-Neighbour on Compute time:    58.4752\n"
     ],
     "output_type": "stream"
    },
    {
     "data": {
      "text/plain": "0"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 3
    }
   ],
   "source": [
    "def kNN_particles_NumPy(particles, k=5):\n",
    "    N = particles.shape[0]\n",
    "    r = (b-a)\n",
    "    r = math.sqrt(np.dot(r,r))\n",
    "    distance_matrix = np.ones((N,N), dtype=np.float64) * r\n",
    "    for i in range(0, N):\n",
    "        pt = particles[i, :]\n",
    "        distance_vector = (particles[:, 0] - pt[0])**2 + (particles[:, 1] - pt[1])**2\n",
    "        distance_matrix[i, :] = numpy.transpose(distance_vector)\n",
    "    \n",
    "    kNN_indices = np.ones((N,k), dtype=np.uint32) * -1\n",
    "    kNN_distances = np.ones((N,k), dtype=np.float64) * r\n",
    "    for i in range(0, N):\n",
    "        for m in range(0, k):\n",
    "            distance_vector = distance_matrix[i, :]\n",
    "            j = distance_vector.argmin()\n",
    "            kNN_indices[i, m] = j\n",
    "            kNN_distances[i, m] = distance_matrix[i, j]\n",
    "            distance_matrix[i, j] = r\n",
    "    return kNN_indices, kNN_distances\n",
    "\n",
    "\n",
    "# ==== Load flow-field data - measure the time ==== #\n",
    "s_io_file_time = timer()\n",
    "f = netcdf.netcdf_file('perlin.nc', 'r')\n",
    "ftimes = f.variables['time'].data\n",
    "fX = f.variables['lon'].data\n",
    "fY = f.variables['lat'].data\n",
    "fU = f.variables['u'].data\n",
    "fV = f.variables['v'].data\n",
    "f.close()\n",
    "e_io_file_time = timer()\n",
    "io_file_time = e_io_file_time-s_io_file_time\n",
    "\n",
    "a = np.array([fX[0], fY[0]])\n",
    "b = np.array([fX[-1], fY[-1]])\n",
    "t_0_N = np.array([ftimes[0], ftimes[-1]])\n",
    "T = t_0_N[1]-t_0_N[0]\n",
    "dt = 12.0 * 60.0 * 60.0\n",
    "sim_steps = int(math.floor(T/dt))\n",
    "total_compute_times = []\n",
    "advect_compute_time = []\n",
    "kNN_compute_time = []\n",
    "\n",
    "sim = Simulation_Benchmark(fX, fY, ftimes, fU, fV)\n",
    "for i in range(0, 512):\n",
    "    pt = (b - a) * np.random.random_sample(2)  + a\n",
    "    sim.add_particle(pt[0], pt[1])\n",
    "\n",
    "# total_compute_times.clear()\n",
    "print(\"==== running the simulation with competing procs ====\")\n",
    "stime_sim = timer()\n",
    "prev_int_proc = -1\n",
    "cur_int_proc = 0\n",
    "while sim.sim_time < sim.sim_end_time:\n",
    "    stime_compute_advect = timer()\n",
    "    sim.advect_once(dt)\n",
    "    etime_compute_advect = timer()\n",
    "    stime_kNN = timer()\n",
    "    kNN_particles_NumPy(sim.particles, k=5)\n",
    "    etime_kNN = timer()\n",
    "    advectTime = etime_compute_advect-stime_compute_advect\n",
    "    knnTime = etime_kNN-stime_kNN\n",
    "    advect_compute_time.append(advectTime)\n",
    "    kNN_compute_time.append(knnTime)\n",
    "    total_compute_times.append(advectTime+knnTime)\n",
    "    proc_done = (sim.sim_time / sim.sim_end_time)*100\n",
    "    cur_int_proc = int(math.floor(proc_done/10))\n",
    "    if prev_int_proc != cur_int_proc:\n",
    "        print(\"Processing at {:10.7f} percent ...\".format(proc_done))\n",
    "    prev_int_proc = cur_int_proc\n",
    "\n",
    "etime_sim = timer()\n",
    "sim_total_time = etime_sim-stime_sim\n",
    "print(\"Total processing time (high-res timer): {:10.7f} sec.\".format(sim_total_time))\n",
    "avg_ptimer_hr = np.array(total_compute_times).mean()\n",
    "print(\"Average processing kernel time (high-res timer): {:10.7f} sec.\".format(avg_ptimer_hr))\n",
    "\n",
    "total_compute_time = np.array(total_compute_times).sum()\n",
    "total_advect_time = np.array(advect_compute_time).sum()\n",
    "total_knn_time = np.array(kNN_compute_time).sum()\n",
    "\n",
    "compute_to_total_ratio = total_compute_time / (sim_total_time+io_file_time)\n",
    "compute_to_iototal = total_compute_time / (sim.io_mem_time+io_file_time)\n",
    "io_to_sim_ratio = sim.io_mem_time / (sim.compute_time+sim.io_mem_time)\n",
    "advect_to_sim = sim.compute_time / (sim.compute_time+sim.io_mem_time)\n",
    "advect_to_iosim = sim.compute_time / sim.io_mem_time+io_file_time\n",
    "advect_compute_percentage = (total_advect_time / total_compute_time) * 100.0\n",
    "knn_compute_percentage = (total_knn_time / total_compute_time) * 100.0\n",
    "\n",
    "total_compute_time_Numpy = total_compute_time\n",
    "total_advect_time_Numpy = total_advect_time\n",
    "total_knn_time_Numpy = total_knn_time\n",
    "\n",
    "print(\"Compute percentage of runtime:                       {:10.7f}\".format(compute_to_total_ratio*100.0))\n",
    "print(\"Compute percentage simulation time (Advection-only): {:10.7f}\".format(advect_to_sim*100.0))\n",
    "print(\"I/O percentage of simulation time:                   {:10.7f}\".format(io_to_sim_ratio*100.0))\n",
    "print(\"------------------------------------------------------------------\")\n",
    "print(\"Ratio Compute time vs. I/O time:              {:10.7f}\".format(compute_to_iototal))\n",
    "print(\"Ratio Advection time vs. I/O-simulation time: {:10.7f}\".format(advect_to_iosim))\n",
    "print(\"------------------------------------------------------------------\")\n",
    "print(\"Percentage of Advection on Compute time:         {:10.4f}\".format(advect_compute_percentage))\n",
    "print(\"Percentage of Nearest-Neighbour on Compute time: {:10.4f}\".format(knn_compute_percentage))\n",
    "del sim\n",
    "del ftimes\n",
    "del fX\n",
    "del fY\n",
    "del fU\n",
    "del fV\n",
    "del total_compute_times\n",
    "del advect_compute_time\n",
    "del kNN_compute_time\n",
    "gc.collect()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We see that this change made a *huge* difference by cutting the execution time from *>500s* to just *~ 20s* - a speed-up of 25 times!\n",
    "We also see that this shift is attributed to the kNN search alone: where before *>99%* of the runtime was spent to compute the kNN, we now spend *just above 50%* of the time to do the kNN computation.\n",
    "\n",
    "Can we do better ?"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Optimisation 2: Use *SciPy* kNN search\n",
    "\n",
    "Up until now, we followed a simple procedure:\n",
    "\n",
    "1. compute the distance metric from each point to each other point\n",
    "2. select the indices of the points with the k shortest distances\n",
    "\n",
    "This procedure is knows as a *greedy* or *brute-force* algorithm. It works for all cases without prior assumptions on data distribution, dimensionality, point density, and so forth.\n",
    "It's conceptually trivial (i.e. )not really breaking any 'new ground' here), but it is also *unbearably* slow.\n",
    "\n",
    "There are smarter algorithm, especially when executing those searches over-and-over again. In this case, organising the element search in a *tree* can lead to drastic improvements.\n",
    "That algorithm is also known as *kD-Tree*: cluster all data instances (i.e. all entities; all rows of a matrix) according to their *k*-dimensional distance. Important to note here is that \n",
    "the *k* of *kD-Tree* has nothing to do with the *k* in *k-nearest neighbour search* - in our example, the *k* of our *kD-Tree* will be 3, whereas the *k* of our *kNN* will be 5.\n",
    "\n",
    "Using **SciPy** we can speed up both the *brute-force* algorithm as well as compare it to the *kD-Tree algorithm*. Let's see how that goes and how fast that is."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "from scipy.spatial import cKDTree\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "def kNN_particles_SciPy_kdtree(particles=np.zeros((2,2)), k=5):\n",
    "    tree = cKDTree(particles)\n",
    "    kNN_distances, kNN_indices = tree.query(particles, k=k)\n",
    "    return kNN_indices, kNN_distances\n",
    "\n",
    "def kNN_particles_SciPy(particles=np.zeros((2,2)), k=5):\n",
    "    N = particles.shape[0]\n",
    "    r = (b-a)\n",
    "    r = math.sqrt(np.dot(r,r))\n",
    "    distance_matrix = cdist(particles, particles, metric='seuclidean')\n",
    "    kNN_indices = np.ones((N,k), dtype=np.uint32) * -1\n",
    "    kNN_distances = np.ones((N,k), dtype=np.float64) * r\n",
    "    for i in range(0, N):\n",
    "        for m in range(0, k):\n",
    "            distance_vector = distance_matrix[i, :]\n",
    "            j = distance_vector.argmin()\n",
    "            kNN_indices[i, m] = j\n",
    "            kNN_distances[i, m] = distance_matrix[i, j]\n",
    "            distance_matrix[i, j] = r\n",
    "    return kNN_indices, kNN_distances"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stderr",
     "text": [
      "/home/ckehl/.local/lib/python3.6/site-packages/scipy/io/netcdf.py:314: RuntimeWarning: Cannot close a netcdf_file opened with mmap=True, when netcdf_variables or arrays referring to its data still exist. All data arrays obtained from such files refer directly to data on disk, and must be copied before the file can be cleanly closed. (See netcdf_file docstring for more information on mmap.)\n",
      "  ), category=RuntimeWarning)\n"
     ],
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": [
      "==== running the simulation with competing procs ====\n",
      "Processing at  0.1351351 percent ...\n",
      "Processing at 10.0000000 percent ...\n",
      "Processing at 20.0000000 percent ...\n",
      "Processing at 30.0000000 percent ...\n",
      "Processing at 40.0000000 percent ...\n",
      "Processing at 50.0000000 percent ...\n",
      "Processing at 60.0000000 percent ...\n",
      "Processing at 70.0000000 percent ...\n",
      "Processing at 80.0000000 percent ...\n",
      "Processing at 90.0000000 percent ...\n",
      "Processing at 100.0000000 percent ...\n",
      "Total processing time (high-res timer): 13.5994487 sec.\n",
      "Average processing kernel time (high-res timer):  0.0183343 sec.\n",
      "==== Compute particle-kNN via SciPy using the brute-force algorithm ====\n",
      "Compute percentage of runtime:                       99.7590180\n",
      "Compute percentage simulation time (Advection-only): 92.8156144\n",
      "I/O percentage of simulation time:                    7.1843856\n",
      "------------------------------------------------------------------\n",
      "Ratio Compute time vs. I/O time:              24.6091038\n",
      "Ratio Advection time vs. I/O-simulation time: 12.9197784\n",
      "------------------------------------------------------------------\n",
      "Percentage of Advection on Compute time:            57.2348\n",
      "Percentage of Nearest-Neighbour on Compute time:    42.7652\n"
     ],
     "output_type": "stream"
    },
    {
     "data": {
      "text/plain": "0"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 7
    }
   ],
   "source": [
    "# ==== Load flow-field data - measure the time ==== #\n",
    "s_io_file_time = timer()\n",
    "f = netcdf.netcdf_file('perlin.nc', 'r')\n",
    "ftimes = f.variables['time'].data\n",
    "fX = f.variables['lon'].data\n",
    "fY = f.variables['lat'].data\n",
    "fU = f.variables['u'].data\n",
    "fV = f.variables['v'].data\n",
    "f.close()\n",
    "e_io_file_time = timer()\n",
    "io_file_time = e_io_file_time-s_io_file_time\n",
    "\n",
    "a = np.array([fX[0], fY[0]])\n",
    "b = np.array([fX[-1], fY[-1]])\n",
    "t_0_N = np.array([ftimes[0], ftimes[-1]])\n",
    "T = t_0_N[1]-t_0_N[0]\n",
    "dt = 12.0 * 60.0 * 60.0\n",
    "sim_steps = int(math.floor(T/dt))\n",
    "total_compute_times = []\n",
    "advect_compute_time = []\n",
    "kNN_compute_time = []\n",
    "\n",
    "sim = Simulation_Benchmark(fX, fY, ftimes, fU, fV)\n",
    "for i in range(0, 512):\n",
    "    pt = (b - a) * np.random.random_sample(2)  + a\n",
    "    sim.add_particle(pt[0], pt[1])\n",
    "\n",
    "# total_compute_times.clear()\n",
    "print(\"==== running the simulation with competing procs ====\")\n",
    "stime_sim = timer()\n",
    "prev_int_proc = -1\n",
    "cur_int_proc = 0\n",
    "while sim.sim_time < sim.sim_end_time:\n",
    "    stime_compute_advect = timer()\n",
    "    sim.advect_once(dt)\n",
    "    etime_compute_advect = timer()\n",
    "    stime_kNN = timer()\n",
    "    kNN_particles_SciPy(sim.particles, k=5)\n",
    "    etime_kNN = timer()\n",
    "    advectTime = etime_compute_advect-stime_compute_advect\n",
    "    knnTime = etime_kNN-stime_kNN\n",
    "    advect_compute_time.append(advectTime)\n",
    "    kNN_compute_time.append(knnTime)\n",
    "    total_compute_times.append(advectTime+knnTime)\n",
    "    proc_done = (sim.sim_time / sim.sim_end_time)*100\n",
    "    cur_int_proc = int(math.floor(proc_done/10))\n",
    "    if prev_int_proc != cur_int_proc:\n",
    "        print(\"Processing at {:10.7f} percent ...\".format(proc_done))\n",
    "    prev_int_proc = cur_int_proc\n",
    "\n",
    "etime_sim = timer()\n",
    "sim_total_time = etime_sim-stime_sim\n",
    "print(\"Total processing time (high-res timer): {:10.7f} sec.\".format(sim_total_time))\n",
    "avg_ptimer_hr = np.array(total_compute_times).mean()\n",
    "print(\"Average processing kernel time (high-res timer): {:10.7f} sec.\".format(avg_ptimer_hr))\n",
    "\n",
    "total_compute_time = np.array(total_compute_times).sum()\n",
    "total_advect_time = np.array(advect_compute_time).sum()\n",
    "total_knn_time = np.array(kNN_compute_time).sum()\n",
    "\n",
    "compute_to_total_ratio = total_compute_time / (sim_total_time+io_file_time)\n",
    "compute_to_iototal = total_compute_time / (sim.io_mem_time+io_file_time)\n",
    "io_to_sim_ratio = sim.io_mem_time / (sim.compute_time+sim.io_mem_time)\n",
    "advect_to_sim = sim.compute_time / (sim.compute_time+sim.io_mem_time)\n",
    "advect_to_iosim = sim.compute_time / sim.io_mem_time+io_file_time\n",
    "advect_compute_percentage = (total_advect_time / total_compute_time) * 100.0\n",
    "knn_compute_percentage = (total_knn_time / total_compute_time) * 100.0\n",
    "\n",
    "total_compute_time_SciPy_512 = total_compute_time\n",
    "total_advect_time_SciPy_512 = total_advect_time\n",
    "total_knn_time_SciPy_512 = total_knn_time\n",
    "\n",
    "print(\"==== Compute particle-kNN via SciPy using the brute-force algorithm ====\")\n",
    "print(\"Compute percentage of runtime:                       {:10.7f}\".format(compute_to_total_ratio*100.0))\n",
    "print(\"Compute percentage simulation time (Advection-only): {:10.7f}\".format(advect_to_sim*100.0))\n",
    "print(\"I/O percentage of simulation time:                   {:10.7f}\".format(io_to_sim_ratio*100.0))\n",
    "print(\"------------------------------------------------------------------\")\n",
    "print(\"Ratio Compute time vs. I/O time:              {:10.7f}\".format(compute_to_iototal))\n",
    "print(\"Ratio Advection time vs. I/O-simulation time: {:10.7f}\".format(advect_to_iosim))\n",
    "print(\"------------------------------------------------------------------\")\n",
    "print(\"Percentage of Advection on Compute time:         {:10.4f}\".format(advect_compute_percentage))\n",
    "print(\"Percentage of Nearest-Neighbour on Compute time: {:10.4f}\".format(knn_compute_percentage))\n",
    "del sim\n",
    "del ftimes\n",
    "del fX\n",
    "del fY\n",
    "del fU\n",
    "del fV\n",
    "del total_compute_times\n",
    "del advect_compute_time\n",
    "del kNN_compute_time\n",
    "gc.collect()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stderr",
     "text": [
      "/home/ckehl/.local/lib/python3.6/site-packages/scipy/io/netcdf.py:314: RuntimeWarning: Cannot close a netcdf_file opened with mmap=True, when netcdf_variables or arrays referring to its data still exist. All data arrays obtained from such files refer directly to data on disk, and must be copied before the file can be cleanly closed. (See netcdf_file docstring for more information on mmap.)\n",
      "  ), category=RuntimeWarning)\n"
     ],
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": [
      "==== running the simulation with competing procs ====\n",
      "Processing at  0.1351351 percent ...\n",
      "Processing at 10.0000000 percent ...\n",
      "Processing at 20.0000000 percent ...\n",
      "Processing at 30.0000000 percent ...\n",
      "Processing at 40.0000000 percent ...\n",
      "Processing at 50.0000000 percent ...\n",
      "Processing at 60.0000000 percent ...\n",
      "Processing at 70.0000000 percent ...\n",
      "Processing at 80.0000000 percent ...\n",
      "Processing at 90.0000000 percent ...\n",
      "Processing at 100.0000000 percent ...\n",
      "Total processing time (high-res timer):  8.2945392 sec.\n",
      "Average processing kernel time (high-res timer):  0.0111754 sec.\n",
      "==== Compute particle-kNN via SciPy using the kD-Tree algorithm ====\n",
      "Compute percentage of runtime:                       99.6942595\n",
      "Compute percentage simulation time (Advection-only): 93.2359472\n",
      "I/O percentage of simulation time:                    6.7640528\n",
      "------------------------------------------------------------------\n",
      "Ratio Compute time vs. I/O time:              16.7245541\n",
      "Ratio Advection time vs. I/O-simulation time: 13.7846508\n",
      "------------------------------------------------------------------\n",
      "Percentage of Advection on Compute time:            89.5208\n",
      "Percentage of Nearest-Neighbour on Compute time:    10.4792\n"
     ],
     "output_type": "stream"
    },
    {
     "data": {
      "text/plain": "0"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 8
    }
   ],
   "source": [
    "# ==== Load flow-field data - measure the time ==== #\n",
    "s_io_file_time = timer()\n",
    "f = netcdf.netcdf_file('perlin.nc', 'r')\n",
    "ftimes = f.variables['time'].data\n",
    "fX = f.variables['lon'].data\n",
    "fY = f.variables['lat'].data\n",
    "fU = f.variables['u'].data\n",
    "fV = f.variables['v'].data\n",
    "f.close()\n",
    "e_io_file_time = timer()\n",
    "io_file_time = e_io_file_time-s_io_file_time\n",
    "\n",
    "a = np.array([fX[0], fY[0]])\n",
    "b = np.array([fX[-1], fY[-1]])\n",
    "t_0_N = np.array([ftimes[0], ftimes[-1]])\n",
    "T = t_0_N[1]-t_0_N[0]\n",
    "dt = 12.0 * 60.0 * 60.0\n",
    "sim_steps = int(math.floor(T/dt))\n",
    "total_compute_times = []\n",
    "advect_compute_time = []\n",
    "kNN_compute_time = []\n",
    "\n",
    "sim = Simulation_Benchmark(fX, fY, ftimes, fU, fV)\n",
    "for i in range(0, 512):\n",
    "    pt = (b - a) * np.random.random_sample(2)  + a\n",
    "    sim.add_particle(pt[0], pt[1])\n",
    "\n",
    "# total_compute_times.clear()\n",
    "print(\"==== running the simulation with competing procs ====\")\n",
    "stime_sim = timer()\n",
    "prev_int_proc = -1\n",
    "cur_int_proc = 0\n",
    "while sim.sim_time < sim.sim_end_time:\n",
    "    stime_compute_advect = timer()\n",
    "    sim.advect_once(dt)\n",
    "    etime_compute_advect = timer()\n",
    "    stime_kNN = timer()\n",
    "    kNN_particles_SciPy_kdtree(sim.particles, k=5)\n",
    "    etime_kNN = timer()\n",
    "    advectTime = etime_compute_advect-stime_compute_advect\n",
    "    knnTime = etime_kNN-stime_kNN\n",
    "    advect_compute_time.append(advectTime)\n",
    "    kNN_compute_time.append(knnTime)\n",
    "    total_compute_times.append(advectTime+knnTime)\n",
    "    proc_done = (sim.sim_time / sim.sim_end_time)*100\n",
    "    cur_int_proc = int(math.floor(proc_done/10))\n",
    "    if prev_int_proc != cur_int_proc:\n",
    "        print(\"Processing at {:10.7f} percent ...\".format(proc_done))\n",
    "    prev_int_proc = cur_int_proc\n",
    "\n",
    "etime_sim = timer()\n",
    "sim_total_time = etime_sim-stime_sim\n",
    "print(\"Total processing time (high-res timer): {:10.7f} sec.\".format(sim_total_time))\n",
    "avg_ptimer_hr = np.array(total_compute_times).mean()\n",
    "print(\"Average processing kernel time (high-res timer): {:10.7f} sec.\".format(avg_ptimer_hr))\n",
    "\n",
    "total_compute_time = np.array(total_compute_times).sum()\n",
    "total_advect_time = np.array(advect_compute_time).sum()\n",
    "total_knn_time = np.array(kNN_compute_time).sum()\n",
    "\n",
    "compute_to_total_ratio = total_compute_time / (sim_total_time+io_file_time)\n",
    "compute_to_iototal = total_compute_time / (sim.io_mem_time+io_file_time)\n",
    "io_to_sim_ratio = sim.io_mem_time / (sim.compute_time+sim.io_mem_time)\n",
    "advect_to_sim = sim.compute_time / (sim.compute_time+sim.io_mem_time)\n",
    "advect_to_iosim = sim.compute_time / sim.io_mem_time+io_file_time\n",
    "advect_compute_percentage = (total_advect_time / total_compute_time) * 100.0\n",
    "knn_compute_percentage = (total_knn_time / total_compute_time) * 100.0\n",
    "\n",
    "total_compute_time_SciPy_kd512 = total_compute_time\n",
    "total_advect_time_SciPy_kd512 = total_advect_time\n",
    "total_knn_time_SciPy_kd512 = total_knn_time\n",
    "\n",
    "print(\"==== Compute particle-kNN via SciPy using the kD-Tree algorithm ====\")\n",
    "print(\"Compute percentage of runtime:                       {:10.7f}\".format(compute_to_total_ratio*100.0))\n",
    "print(\"Compute percentage simulation time (Advection-only): {:10.7f}\".format(advect_to_sim*100.0))\n",
    "print(\"I/O percentage of simulation time:                   {:10.7f}\".format(io_to_sim_ratio*100.0))\n",
    "print(\"------------------------------------------------------------------\")\n",
    "print(\"Ratio Compute time vs. I/O time:              {:10.7f}\".format(compute_to_iototal))\n",
    "print(\"Ratio Advection time vs. I/O-simulation time: {:10.7f}\".format(advect_to_iosim))\n",
    "print(\"------------------------------------------------------------------\")\n",
    "print(\"Percentage of Advection on Compute time:         {:10.4f}\".format(advect_compute_percentage))\n",
    "print(\"Percentage of Nearest-Neighbour on Compute time: {:10.4f}\".format(knn_compute_percentage))\n",
    "del sim\n",
    "del ftimes\n",
    "del fX\n",
    "del fY\n",
    "del fU\n",
    "del fV\n",
    "del total_compute_times\n",
    "del advect_compute_time\n",
    "del kNN_compute_time\n",
    "gc.collect()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "When observing and *interpreting* our measured results, it's important to note here that *SciPy* is a nice toolbox on top of NumPy that includes some \n",
    "specific, well know algorithms for geometry (e.g. nearest-neighbours), statistics, inter- and extrapolation and many more. There are other, domain-specific, comparable package (just like *SciPy*) sitting on top of NumPy, such as **scikits-learn** (sklearn) or **scikits-image**.\n",
    "If the specific function you search for is in that toolbox, and all your other data are in **_NumPy_**, then it's usually good to use those packages instead of re-inventing the wheel with JIT or C-Bindings.\n",
    "That said, the SciPy-trick doesn't work all the time - some algorithms are just not available in SciPy, or just not convertable or expressable in linear-algebra form.\n",
    "In order to execute those functions *at high speed* and *inside Python*, we will need to use specific C-bindings, such as provide via **JIT**."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Optimisation 3: Write the whole kNN search in *Numba*'s Just-in-Time (JIT) C-code\n",
    "\n",
    "What is *Just-in-Time (JIT)* compilation ? (What is *compilation* ?)\n",
    "\n",
    "As said before: the computer CPU, in the very end, only understands C-like code (or, more specifically: C-compiled binary code).\n",
    "Python itself is somehow build with C - you can see this because *python* itself is just an executable program.\n",
    "Python can interface pre-compiled C-code with its Python translation natively (more to that later). Another possibility is to write code in **_native_** Python, which is translated into C-code during Python-code execution.\n",
    "This translation of Python code into C-code *when running* the script is called *Just-in-Time (JIT)* compilation (in contrast to the more common *pre-compiled binaries*).\n",
    "\n",
    "Why would we want to do that ?\n",
    "Can I transform *any* piece of Python code into fast C-code via JIT compilation ? **NO**\n",
    "\n",
    "Coding *JIT* snippets is constrained by certain conditions:\n",
    "- JIT only wraps *individual functions* or full *classes* (latter is more difficult), so you cannot just JIT-compile a few code-lines by choice\n",
    "- JIT only accepts function inputs from either *native Python* or *NumPy* -> if you have other classes, objects or packages as input, it will not work; if the parameter is a function handle, it will not work;\n",
    "- Because the JIT does a translation to C, you need to (a) know the types of our parameter variables, (b) keep these variables fixed and (c) do not mix fields of different types\n",
    "- with JIT, you loose all typeless coding stuff in the target function\n",
    "- the code inside the JIT function can only use *functions*, *data types* and *instructions* that are native in either (a) native Python or (b) NumPy\n",
    "- you cannot use other packages in JIT, such as *SciPy*, *sklearn* or others, unless they are declared inside the JIT context\n",
    "\n",
    "Due to those constraints, producing working JIT-code is actually not *that* easy unless you know the function you want to 'jittify' inside-out.\n",
    "\n",
    "How can we actually use JIT code ? 1. way (modern): **Numba**\n",
    "\n",
    "Our starting point of the JIT code is, due to the above-listed constraints, the Python-only implementation from the very beginning."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stderr",
     "text": [
      "/home/ckehl/.local/lib/python3.6/site-packages/scipy/io/netcdf.py:314: RuntimeWarning: Cannot close a netcdf_file opened with mmap=True, when netcdf_variables or arrays referring to its data still exist. All data arrays obtained from such files refer directly to data on disk, and must be copied before the file can be cleanly closed. (See netcdf_file docstring for more information on mmap.)\n",
      "  ), category=RuntimeWarning)\n"
     ],
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": [
      "==== running the simulation with competing procs ====\n",
      "Processing at  0.1351351 percent ...\n",
      "Processing at 10.0000000 percent ...\n",
      "Processing at 20.0000000 percent ...\n",
      "Processing at 30.0000000 percent ...\n",
      "Processing at 40.0000000 percent ...\n",
      "Processing at 50.0000000 percent ...\n",
      "Processing at 60.0000000 percent ...\n",
      "Processing at 70.0000000 percent ...\n",
      "Processing at 80.0000000 percent ...\n",
      "Processing at 90.0000000 percent ...\n",
      "Processing at 100.0000000 percent ...\n",
      "Total processing time (high-res timer): 22.7322796 sec.\n",
      "Average processing kernel time (high-res timer):  0.0306646 sec.\n",
      "Compute percentage of runtime:                       99.8168069\n",
      "Compute percentage simulation time (Advection-only): 92.5641894\n",
      "I/O percentage of simulation time:                    7.4358106\n",
      "------------------------------------------------------------------\n",
      "Ratio Compute time vs. I/O time:              37.9409767\n",
      "Ratio Advection time vs. I/O-simulation time: 12.4496398\n",
      "------------------------------------------------------------------\n",
      "Percentage of Advection on Compute time:            35.8929\n",
      "Percentage of Nearest-Neighbour on Compute time:    64.1071\n"
     ],
     "output_type": "stream"
    },
    {
     "data": {
      "text/plain": "22836"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 9
    }
   ],
   "source": [
    "import numba\n",
    "\n",
    "@numba.jit(\"void(float32[:,:], int32[:,:], float64[:,:], int32)\", nopython=True)\n",
    "def kNN_particles_Numba(particles, kNN_indices, kNN_distances, k=5):\n",
    "    N = particles.shape[0]\n",
    "    r = (b-a)\n",
    "    r = math.sqrt(np.dot(r,r))\n",
    "    distance_matrix = np.ones((N,N), dtype=np.float64) * r\n",
    "    for i in range(0, N):\n",
    "        for j in range (i, N):\n",
    "            if i==j:\n",
    "                distance_matrix[i,j] = .0\n",
    "                continue\n",
    "            dv = particles[i, 0:1]-particles[j, 0:1]\n",
    "            dv_len_sqr = dv[0]*dv[0]+dv[1]*dv[1]\n",
    "            distance_matrix[i, j] = dv_len_sqr\n",
    "            distance_matrix[j, i] = dv_len_sqr\n",
    "\n",
    "    for i in range(0, N):\n",
    "        for j in range (0, N):\n",
    "            if i==j:\n",
    "                continue\n",
    "            m = 0\n",
    "            while (m<k) and ((kNN_indices[i, m] < 0) or (kNN_distances[i, m] <= distance_matrix[i, j])):\n",
    "                m += 1\n",
    "            if not m<k:\n",
    "                continue\n",
    "            l = k-1\n",
    "            while l>m:\n",
    "                kNN_indices[i, l] = kNN_indices[i, l-1]\n",
    "                kNN_distances[i, l] = kNN_distances[i, l-1]\n",
    "            kNN_indices[i, m] = j\n",
    "            kNN_distances[i, m] = distance_matrix[i, j]\n",
    "    return\n",
    "\n",
    "\n",
    "# ==== Load flow-field data - measure the time ==== #\n",
    "s_io_file_time = timer()\n",
    "f = netcdf.netcdf_file('perlin.nc', 'r')\n",
    "ftimes = f.variables['time'].data\n",
    "fX = f.variables['lon'].data\n",
    "fY = f.variables['lat'].data\n",
    "fU = f.variables['u'].data\n",
    "fV = f.variables['v'].data\n",
    "f.close()\n",
    "e_io_file_time = timer()\n",
    "io_file_time = e_io_file_time-s_io_file_time\n",
    "\n",
    "a = np.array([fX[0], fY[0]])\n",
    "b = np.array([fX[-1], fY[-1]])\n",
    "t_0_N = np.array([ftimes[0], ftimes[-1]])\n",
    "T = t_0_N[1]-t_0_N[0]\n",
    "dt = 12.0 * 60.0 * 60.0\n",
    "sim_steps = int(math.floor(T/dt))\n",
    "total_compute_times = []\n",
    "advect_compute_time = []\n",
    "kNN_compute_time = []\n",
    "\n",
    "sim = Simulation_Benchmark(fX, fY, ftimes, fU, fV)\n",
    "for i in range(0, 512):\n",
    "    pt = (b - a) * np.random.random_sample(2)  + a\n",
    "    sim.add_particle(pt[0], pt[1])\n",
    "\n",
    "# total_compute_times.clear()\n",
    "print(\"==== running the simulation with competing procs ====\")\n",
    "rv = (b-a)\n",
    "r = math.sqrt(np.dot(rv,rv))\n",
    "N = len(sim)\n",
    "k = 5\n",
    "kNN_indices = np.ones((N,k), dtype=np.int32) * -1\n",
    "kNN_distances = np.ones((N,k), dtype=np.float64) * r\n",
    "stime_sim = timer()\n",
    "prev_int_proc = -1\n",
    "cur_int_proc = 0\n",
    "while sim.sim_time < sim.sim_end_time:\n",
    "    stime_compute_advect = timer()\n",
    "    sim.advect_once(dt)\n",
    "    etime_compute_advect = timer()\n",
    "    stime_kNN = timer()\n",
    "    kNN_distances.fill(r)\n",
    "    kNN_indices.fill(np.int32(-1))\n",
    "    kNN_particles_Numba(sim.particles, kNN_indices, kNN_distances, k)\n",
    "    etime_kNN = timer()\n",
    "    advectTime = etime_compute_advect-stime_compute_advect\n",
    "    knnTime = etime_kNN-stime_kNN\n",
    "    advect_compute_time.append(advectTime)\n",
    "    kNN_compute_time.append(knnTime)\n",
    "    total_compute_times.append(advectTime+knnTime)\n",
    "    proc_done = (sim.sim_time / sim.sim_end_time)*100\n",
    "    cur_int_proc = int(math.floor(proc_done/10))\n",
    "    if prev_int_proc != cur_int_proc:\n",
    "        print(\"Processing at {:10.7f} percent ...\".format(proc_done))\n",
    "    prev_int_proc = cur_int_proc\n",
    "\n",
    "etime_sim = timer()\n",
    "sim_total_time = etime_sim-stime_sim\n",
    "print(\"Total processing time (high-res timer): {:10.7f} sec.\".format(sim_total_time))\n",
    "avg_ptimer_hr = np.array(total_compute_times).mean()\n",
    "print(\"Average processing kernel time (high-res timer): {:10.7f} sec.\".format(avg_ptimer_hr))\n",
    "\n",
    "total_compute_time = np.array(total_compute_times).sum()\n",
    "total_advect_time = np.array(advect_compute_time).sum()\n",
    "total_knn_time = np.array(kNN_compute_time).sum()\n",
    "\n",
    "compute_to_total_ratio = total_compute_time / (sim_total_time+io_file_time)\n",
    "compute_to_iototal = total_compute_time / (sim.io_mem_time+io_file_time)\n",
    "io_to_sim_ratio = sim.io_mem_time / (sim.compute_time+sim.io_mem_time)\n",
    "advect_to_sim = sim.compute_time / (sim.compute_time+sim.io_mem_time)\n",
    "advect_to_iosim = sim.compute_time / sim.io_mem_time+io_file_time\n",
    "advect_compute_percentage = (total_advect_time / total_compute_time) * 100.0\n",
    "knn_compute_percentage = (total_knn_time / total_compute_time) * 100.0\n",
    "\n",
    "total_compute_time_Numba_512 = total_compute_time\n",
    "total_advect_time_Numba_512 = total_advect_time\n",
    "total_knn_time_Numba_512 = total_knn_time\n",
    "\n",
    "print(\"Compute percentage of runtime:                       {:10.7f}\".format(compute_to_total_ratio*100.0))\n",
    "print(\"Compute percentage simulation time (Advection-only): {:10.7f}\".format(advect_to_sim*100.0))\n",
    "print(\"I/O percentage of simulation time:                   {:10.7f}\".format(io_to_sim_ratio*100.0))\n",
    "print(\"------------------------------------------------------------------\")\n",
    "print(\"Ratio Compute time vs. I/O time:              {:10.7f}\".format(compute_to_iototal))\n",
    "print(\"Ratio Advection time vs. I/O-simulation time: {:10.7f}\".format(advect_to_iosim))\n",
    "print(\"------------------------------------------------------------------\")\n",
    "print(\"Percentage of Advection on Compute time:         {:10.4f}\".format(advect_compute_percentage))\n",
    "print(\"Percentage of Nearest-Neighbour on Compute time: {:10.4f}\".format(knn_compute_percentage))\n",
    "del sim\n",
    "del ftimes\n",
    "del fX\n",
    "del fY\n",
    "del fU\n",
    "del fV\n",
    "del total_compute_times\n",
    "del advect_compute_time\n",
    "del kNN_compute_time\n",
    "del kNN_indices\n",
    "del kNN_distances\n",
    "gc.collect()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We observe the following:\n",
    "- JIT is on-par with the NumPy implementation - that's quite a common result for small functions and code section\n",
    "- JIT is slower than SciPy (or, at least: the kD-Tree-based algorithm)\n",
    "\n",
    "On the latter observation point: the data size (here: 512 particles) of our example is tiny, so that tree-construction and distance computation is simple. \n",
    "If we were to increase *N = 2048* or larger, we will start to see a reversal in the measurements. \n",
    "For very large (i.e. **_big_**) data, the kD-Tree algorithm in SciPy is slower than greedy algorithm, if the particle positions change and hence the tree needs to be revuild at each iteration."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stderr",
     "text": [
      "/home/ckehl/.local/lib/python3.6/site-packages/scipy/io/netcdf.py:314: RuntimeWarning: Cannot close a netcdf_file opened with mmap=True, when netcdf_variables or arrays referring to its data still exist. All data arrays obtained from such files refer directly to data on disk, and must be copied before the file can be cleanly closed. (See netcdf_file docstring for more information on mmap.)\n",
      "  ), category=RuntimeWarning)\n"
     ],
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": [
      "==== running the simulation with competing procs ====\n",
      "Processing at  0.1351351 percent ...\n",
      "Processing at 10.0000000 percent ...\n",
      "Processing at 20.0000000 percent ...\n",
      "Processing at 30.0000000 percent ...\n",
      "Processing at 40.0000000 percent ...\n",
      "Processing at 50.0000000 percent ...\n",
      "Processing at 60.0000000 percent ...\n",
      "Processing at 70.0000000 percent ...\n",
      "Processing at 80.0000000 percent ...\n",
      "Processing at 90.0000000 percent ...\n",
      "Processing at 100.0000000 percent ...\n",
      "Total processing time (high-res timer): 191.4964308 sec.\n",
      "==== simulation run with 2^11 instead of 2^9 particles ====\n",
      "Percentage of Advection on Compute time (with Numba):     9.3665\n",
      "Percentage of Nearest-Neighbour on Compute time (with Numba):    90.6335\n",
      "Percentage of Advection on Compute time (with SciPy):    34.1590\n",
      "Percentage of Nearest-Neighbour on Compute time (with SciPy):    65.8410\n"
     ],
     "output_type": "stream"
    },
    {
     "data": {
      "text/plain": "0"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 10
    }
   ],
   "source": [
    "# ==== Load flow-field data - measure the time ==== #\n",
    "s_io_file_time = timer()\n",
    "f = netcdf.netcdf_file('perlin.nc', 'r')\n",
    "ftimes = f.variables['time'].data\n",
    "fX = f.variables['lon'].data\n",
    "fY = f.variables['lat'].data\n",
    "fU = f.variables['u'].data\n",
    "fV = f.variables['v'].data\n",
    "f.close()\n",
    "e_io_file_time = timer()\n",
    "io_file_time = e_io_file_time-s_io_file_time\n",
    "\n",
    "a = np.array([fX[0], fY[0]])\n",
    "b = np.array([fX[-1], fY[-1]])\n",
    "t_0_N = np.array([ftimes[0], ftimes[-1]])\n",
    "T = t_0_N[1]-t_0_N[0]\n",
    "dt = 12.0 * 60.0 * 60.0\n",
    "sim_steps = int(math.floor(T/dt))\n",
    "total_compute_times_Numba2k = []\n",
    "total_compute_times_SciPy2k = []\n",
    "advect_compute_time = []\n",
    "kNN_compute_time_Numba2k = []\n",
    "kNN_compute_time_SciPy2k = []\n",
    "\n",
    "sim = Simulation_Benchmark(fX, fY, ftimes, fU, fV)\n",
    "for i in range(0, 2048):\n",
    "    pt = (b - a) * np.random.random_sample(2)  + a\n",
    "    sim.add_particle(pt[0], pt[1])\n",
    "\n",
    "# total_compute_times.clear()\n",
    "print(\"==== running the simulation with competing procs ====\")\n",
    "rv = (b-a)\n",
    "r = math.sqrt(np.dot(rv,rv))\n",
    "N = len(sim)\n",
    "k = 5\n",
    "kNN_indices = np.ones((N,k), dtype=np.int32) * -1\n",
    "kNN_distances = np.ones((N,k), dtype=np.float64) * r\n",
    "stime_sim = timer()\n",
    "prev_int_proc = -1\n",
    "cur_int_proc = 0\n",
    "while sim.sim_time < sim.sim_end_time:\n",
    "    stime_compute_advect = timer()\n",
    "    sim.advect_once(dt)\n",
    "    etime_compute_advect = timer()\n",
    "    stime_kNN_Numba2k = timer()\n",
    "    kNN_distances.fill(r)\n",
    "    kNN_indices.fill(np.int32(-1))\n",
    "    kNN_particles_Numba(sim.particles, kNN_indices, kNN_distances, k)\n",
    "    etime_kNN_Numba2k = timer()\n",
    "    stime_kNN_SciPy2k = timer()\n",
    "    kNN_particles_SciPy(sim.particles, k=5)\n",
    "    etime_kNN_SciPy2k = timer()\n",
    "    advectTime = etime_compute_advect-stime_compute_advect\n",
    "    knnTime_Numba2k = etime_kNN_Numba2k-stime_kNN_Numba2k\n",
    "    knnTime_SciPy2k = etime_kNN_SciPy2k-stime_kNN_SciPy2k\n",
    "    advect_compute_time.append(advectTime)\n",
    "    kNN_compute_time_Numba2k.append(knnTime_Numba2k)\n",
    "    kNN_compute_time_SciPy2k.append(knnTime_SciPy2k)\n",
    "    total_compute_times_Numba2k.append(advectTime+knnTime_Numba2k)\n",
    "    total_compute_times_SciPy2k.append(advectTime+knnTime_SciPy2k)\n",
    "    proc_done = (sim.sim_time / sim.sim_end_time)*100\n",
    "    cur_int_proc = int(math.floor(proc_done/10))\n",
    "    if prev_int_proc != cur_int_proc:\n",
    "        print(\"Processing at {:10.7f} percent ...\".format(proc_done))\n",
    "    prev_int_proc = cur_int_proc\n",
    "\n",
    "etime_sim = timer()\n",
    "sim_total_time = etime_sim-stime_sim\n",
    "print(\"Total processing time (high-res timer): {:10.7f} sec.\".format(sim_total_time))\n",
    "# avg_ptimer_hr = np.array(total_compute_times).mean()\n",
    "# print(\"Average processing kernel time (high-res timer): {:10.7f} sec.\".format(avg_ptimer_hr))\n",
    "\n",
    "total_compute_time_Numba_2k = np.array(total_compute_times_Numba2k).sum()\n",
    "total_advect_time_Numba_2k = np.array(advect_compute_time).sum()\n",
    "total_knn_time_Numba_2k = np.array(kNN_compute_time_Numba2k).sum()\n",
    "\n",
    "total_compute_time_SciPy_2k = np.array(total_compute_times_SciPy2k).sum()\n",
    "total_advect_time_SciPy_2k = np.array(advect_compute_time).sum()\n",
    "total_knn_time_SciPy_2k = np.array(kNN_compute_time_SciPy2k).sum()\n",
    "\n",
    "advect_compute_percentage_numba = (total_advect_time_Numba_2k / total_compute_time_Numba_2k) * 100.0\n",
    "advect_compute_percentage_scipy = (total_advect_time_SciPy_2k / total_compute_time_SciPy_2k) * 100.0\n",
    "knn_compute_percentage_numba = (total_knn_time_Numba_2k / total_compute_time_Numba_2k) * 100.0\n",
    "knn_compute_percentage_scipy = (total_knn_time_SciPy_2k / total_compute_time_SciPy_2k) * 100.0\n",
    "\n",
    "print(\"==== simulation run with 2^11 instead of 2^9 particles ====\")\n",
    "\n",
    "print(\"Percentage of Advection on Compute time (with Numba): {:10.4f}\".format(advect_compute_percentage_numba))\n",
    "print(\"Percentage of Nearest-Neighbour on Compute time (with Numba): {:10.4f}\".format(knn_compute_percentage_numba))\n",
    "print(\"Percentage of Advection on Compute time (with SciPy): {:10.4f}\".format(advect_compute_percentage_scipy))\n",
    "print(\"Percentage of Nearest-Neighbour on Compute time (with SciPy): {:10.4f}\".format(knn_compute_percentage_scipy))\n",
    "del sim\n",
    "del ftimes\n",
    "del fX\n",
    "del fY\n",
    "del fU\n",
    "del fV\n",
    "del total_compute_times_Numba2k\n",
    "del total_compute_times_SciPy2k\n",
    "del advect_compute_time\n",
    "del kNN_compute_time_Numba2k\n",
    "del kNN_compute_time_SciPy2k\n",
    "del kNN_indices\n",
    "del kNN_distances\n",
    "gc.collect()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Optimisation 4: Write the whole kNN search in native C-code and use *ctypes* JIT\n",
    "\n",
    "A 2. way, and slightly older option, to do JIT is the use of the **ctypes** package. For everyone who is familiar with OceanParcels: This is what is actually in use in OceanParcels.\n",
    "The idea of JIT is the same, but *ctypes* actually requires the C-function to be written by the programmer, as there is no simple, automatic translation from *Python* to *C*.\n",
    "The usage and calling convention of *ctypes* is more cumbersome than *Numba*. The advantage of *ctypes* is that it's easy to mix and incorporate more complex, library-interlinked functionality into the JIT-functions than JUST native Python and NumPy.\n",
    "\n",
    "In our example, the C-code is in separate files called `knn_ctypes.h` and `knn_ctypes.c`. Additionally, I created a few super-classes to make the *ctypes*-calling less verbose and more easy-access."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Compiled /var/scratch/workspace/Python/knn_ctypes.c ==> /tmp/PFL-1000/libknn_ctypes.so\n",
      "lib '/tmp/PFL-1000/libknn_ctypes.so' register (count: 1)\n",
      "<CDLL '/tmp/PFL-1000/libknn_ctypes.so', handle 2a4aa40 at 0x7f84bb07af60>\n",
      "{'name': 'get_index_columnorder', 'return': <class 'ctypes.c_ulong'>, 'arguments': [<class 'ctypes.c_int'>, <class 'ctypes.c_int'>, <class 'ctypes.c_int'>, <class 'ctypes.c_int'>]}\n",
      "{'name': 'get_index_roworder', 'return': <class 'ctypes.c_ulong'>, 'arguments': [<class 'ctypes.c_int'>, <class 'ctypes.c_int'>, <class 'ctypes.c_int'>, <class 'ctypes.c_int'>]}\n",
      "{'name': 'kNN_particles_ctypes', 'return': None, 'arguments': [<class 'numpy.ctypeslib.ndpointer_<f4_2d_C_CONTIGUOUS'>, <class 'ctypes.c_int'>, <class 'ctypes.c_int'>, <class 'numpy.ctypeslib.ndpointer_<i4_2d_C_CONTIGUOUS'>, <class 'numpy.ctypeslib.ndpointer_<f8_2d_C_CONTIGUOUS'>, <class 'ctypes.c_float'>, <class 'ctypes.c_int'>]}\n",
      "==== running the simulation with competing procs ====\n",
      "Processing at  0.1351351 percent ...\n",
      "Processing at 10.0000000 percent ...\n",
      "Processing at 20.0000000 percent ...\n",
      "Processing at 30.0000000 percent ...\n",
      "Processing at 40.0000000 percent ...\n",
      "Processing at 50.0000000 percent ...\n",
      "Processing at 60.0000000 percent ...\n",
      "Processing at 70.0000000 percent ...\n",
      "Processing at 80.0000000 percent ...\n",
      "Processing at 90.0000000 percent ...\n",
      "Processing at 100.0000000 percent ...\n",
      "Total processing time (high-res timer): 12.3997708 sec.\n",
      "Average processing kernel time (high-res timer):  0.0166997 sec.\n",
      "Compute percentage of runtime:                       99.6529040\n",
      "Compute percentage simulation time (Advection-only): 92.7762440\n",
      "I/O percentage of simulation time:                    7.2237560\n",
      "------------------------------------------------------------------\n",
      "Ratio Compute time vs. I/O time:              20.7850491\n",
      "Ratio Advection time vs. I/O-simulation time: 12.8442442\n",
      "------------------------------------------------------------------\n",
      "Percentage of Advection on Compute time:            67.4951\n",
      "Percentage of Nearest-Neighbour on Compute time:    32.5049\n",
      "lib '/tmp/PFL-1000/libknn_ctypes.so' de-register (count: 0)\n"
     ],
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": [
      "/home/ckehl/.local/lib/python3.6/site-packages/scipy/io/netcdf.py:314: RuntimeWarning: Cannot close a netcdf_file opened with mmap=True, when netcdf_variables or arrays referring to its data still exist. All data arrays obtained from such files refer directly to data on disk, and must be copied before the file can be cleanly closed. (See netcdf_file docstring for more information on mmap.)\n",
      "  ), category=RuntimeWarning)\n",
      "Exception ignored in: <bound method LibraryRegisterC.__del__ of <code_interface.LibraryRegisterC object at 0x7f84bb0e6b38>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/var/scratch/workspace/Python/code_interface.py\", line 51, in __del__\n",
      "    while entry.register_count > 0:\n",
      "AttributeError: 'str' object has no attribute 'register_count'\n"
     ],
     "output_type": "stream"
    },
    {
     "data": {
      "text/plain": "702"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 11
    }
   ],
   "source": [
    "import ctypes\n",
    "from code_interface import *\n",
    "from ctypes import byref\n",
    "c_lib_register = LibraryRegisterC()\n",
    "# ========================= #\n",
    "# 1. Setup and Compilation  #\n",
    "# ========================= #\n",
    "c_lib_register.load(\"knn_ctypes\", src_dir=\"/var/scratch/workspace/Python\")  # the string here is the name of the C-code/header file\n",
    "c_lib_register.register(\"knn_ctypes\")\n",
    "knn_ctypes_interface = c_lib_register.get(\"knn_ctypes\")  # [\"node\"]\n",
    "func_params = []\n",
    "func_params.append({\"name\": \"get_index_columnorder\", \"return\": ctypes.c_ulong, \"arguments\": [ctypes.c_int, ctypes.c_int, ctypes.c_int, ctypes.c_int]})\n",
    "func_params.append({\"name\": \"get_index_roworder\", \"return\": ctypes.c_ulong, \"arguments\": [ctypes.c_int, ctypes.c_int, ctypes.c_int, ctypes.c_int]})\n",
    "func_params.append({\"name\": \"kNN_particles_ctypes\", \"return\": None, \"arguments\": [np.ctypeslib.ndpointer(dtype=np.float32,ndim=2,flags='C_CONTIGUOUS'),  # ctypes.POINTER(np.ctypeslib.as_ctypes_type(np.float64)), \n",
    "                                                                                  ctypes.c_int, \n",
    "                                                                                  ctypes.c_int, \n",
    "                                                                                  np.ctypeslib.ndpointer(dtype=np.int32,ndim=2,flags='C_CONTIGUOUS'),  # ctypes.POINTER(np.ctypeslib.as_ctypes_type(np.int32)), \n",
    "                                                                                  np.ctypeslib.ndpointer(dtype=np.float64,ndim=2,flags='C_CONTIGUOUS'),  # ctypes.POINTER(np.ctypeslib.as_ctypes_type(np.float64)), \n",
    "                                                                                  ctypes.c_float, \n",
    "                                                                                  ctypes.c_int]})\n",
    "c_funcs = knn_ctypes_interface.load_functions(func_params)\n",
    "kNN_particles_ctypes = c_funcs[\"kNN_particles_ctypes\"]\n",
    "\n",
    "# ========================================== #\n",
    "# 2. Load flow-field data - measure the time #\n",
    "# ========================================== #\n",
    "s_io_file_time = timer()\n",
    "f = netcdf.netcdf_file('perlin.nc', 'r')\n",
    "ftimes = f.variables['time'].data\n",
    "fX = f.variables['lon'].data\n",
    "fY = f.variables['lat'].data\n",
    "fU = f.variables['u'].data\n",
    "fV = f.variables['v'].data\n",
    "f.close()\n",
    "e_io_file_time = timer()\n",
    "io_file_time = e_io_file_time-s_io_file_time\n",
    "\n",
    "a = np.array([fX[0], fY[0]])\n",
    "b = np.array([fX[-1], fY[-1]])\n",
    "t_0_N = np.array([ftimes[0], ftimes[-1]])\n",
    "T = t_0_N[1]-t_0_N[0]\n",
    "dt = 12.0 * 60.0 * 60.0\n",
    "sim_steps = int(math.floor(T/dt))\n",
    "total_compute_times = []\n",
    "advect_compute_time = []\n",
    "kNN_compute_time = []\n",
    "\n",
    "sim = Simulation_Benchmark(fX, fY, ftimes, fU, fV)\n",
    "for i in range(0, 512):\n",
    "    pt = (b - a) * np.random.random_sample(2)  + a\n",
    "    sim.add_particle(pt[0], pt[1])\n",
    "\n",
    "#\n",
    "# 3. Execute simulation and NN-search\n",
    "#\n",
    "print(\"==== running the simulation with competing procs ====\")\n",
    "rv = (b-a)\n",
    "r = math.sqrt(np.dot(rv,rv))\n",
    "N = len(sim)\n",
    "k = 5\n",
    "kNN_indices = np.ones((N,k), dtype=np.int32) * -1\n",
    "kNN_distances = np.ones((N,k), dtype=np.float64) * r\n",
    "stime_sim = timer()\n",
    "prev_int_proc = -1\n",
    "cur_int_proc = 0\n",
    "while sim.sim_time < sim.sim_end_time:\n",
    "    stime_compute_advect = timer()\n",
    "    sim.advect_once(dt)\n",
    "    etime_compute_advect = timer()\n",
    "    stime_kNN = timer()\n",
    "    kNN_distances.fill(r)\n",
    "    kNN_indices.fill(np.int32(-1))\n",
    "    #particle_c_data = byref(np.ctypeslib.as_ctypes(sim.particles))\n",
    "    #indices_c_ref = byref(np.ctypeslib.as_ctypes(kNN_indices))\n",
    "    #distances_c_ref = byref(np.ctypeslib.as_ctypes(kNN_distances))\n",
    "    #kNN_particles_ctypes(particle_c_data, sim.particles.shape[0], sim.particles.shape[1], indices_c_ref, distances_c_ref, r, k)\n",
    "    particle_data = sim.particles\n",
    "    kNN_particles_ctypes(particle_data, particle_data.shape[0], particle_data.shape[1], kNN_indices, kNN_distances, r, k)\n",
    "    etime_kNN = timer()\n",
    "    advectTime = etime_compute_advect-stime_compute_advect\n",
    "    knnTime = etime_kNN-stime_kNN\n",
    "    advect_compute_time.append(advectTime)\n",
    "    kNN_compute_time.append(knnTime)\n",
    "    total_compute_times.append(advectTime+knnTime)\n",
    "    proc_done = (sim.sim_time / sim.sim_end_time)*100\n",
    "    cur_int_proc = int(math.floor(proc_done/10))\n",
    "    if prev_int_proc != cur_int_proc:\n",
    "        print(\"Processing at {:10.7f} percent ...\".format(proc_done))\n",
    "    prev_int_proc = cur_int_proc\n",
    "\n",
    "etime_sim = timer()\n",
    "sim_total_time = etime_sim-stime_sim\n",
    "print(\"Total processing time (high-res timer): {:10.7f} sec.\".format(sim_total_time))\n",
    "avg_ptimer_hr = np.array(total_compute_times).mean()\n",
    "print(\"Average processing kernel time (high-res timer): {:10.7f} sec.\".format(avg_ptimer_hr))\n",
    "\n",
    "total_compute_time = np.array(total_compute_times).sum()\n",
    "total_advect_time = np.array(advect_compute_time).sum()\n",
    "total_knn_time = np.array(kNN_compute_time).sum()\n",
    "\n",
    "compute_to_total_ratio = total_compute_time / (sim_total_time+io_file_time)\n",
    "compute_to_iototal = total_compute_time / (sim.io_mem_time+io_file_time)\n",
    "io_to_sim_ratio = sim.io_mem_time / (sim.compute_time+sim.io_mem_time)\n",
    "advect_to_sim = sim.compute_time / (sim.compute_time+sim.io_mem_time)\n",
    "advect_to_iosim = sim.compute_time / sim.io_mem_time+io_file_time\n",
    "advect_compute_percentage = (total_advect_time / total_compute_time) * 100.0\n",
    "knn_compute_percentage = (total_knn_time / total_compute_time) * 100.0\n",
    "\n",
    "total_compute_time_ctypes = total_compute_time\n",
    "total_advect_time_ctypes = total_advect_time\n",
    "total_knn_time_ctypes = total_knn_time\n",
    "\n",
    "print(\"Compute percentage of runtime:                       {:10.7f}\".format(compute_to_total_ratio*100.0))\n",
    "print(\"Compute percentage simulation time (Advection-only): {:10.7f}\".format(advect_to_sim*100.0))\n",
    "print(\"I/O percentage of simulation time:                   {:10.7f}\".format(io_to_sim_ratio*100.0))\n",
    "print(\"------------------------------------------------------------------\")\n",
    "print(\"Ratio Compute time vs. I/O time:              {:10.7f}\".format(compute_to_iototal))\n",
    "print(\"Ratio Advection time vs. I/O-simulation time: {:10.7f}\".format(advect_to_iosim))\n",
    "print(\"------------------------------------------------------------------\")\n",
    "print(\"Percentage of Advection on Compute time:         {:10.4f}\".format(advect_compute_percentage))\n",
    "print(\"Percentage of Nearest-Neighbour on Compute time: {:10.4f}\".format(knn_compute_percentage))\n",
    "\n",
    "#\n",
    "# 4. re-register and clean-up\n",
    "#\n",
    "c_lib_register.deregister(\"knn_ctypes\")\n",
    "del sim\n",
    "del ftimes\n",
    "del fX\n",
    "del fY\n",
    "del fU\n",
    "del fV\n",
    "del c_lib_register\n",
    "del total_compute_times\n",
    "del advect_compute_time\n",
    "del kNN_compute_time\n",
    "del kNN_indices\n",
    "del kNN_distances\n",
    "gc.collect()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Our observations are as follows:\n",
    "- our good, fast implementation of kNN in *native C-code* and its access via *ctypes* is faster than JIT via Numba!\n",
    "- the *ctypes*-JIT is even comparably-fast to SciPy, and can be one of the fastest ways to calculate this k-nearest neighbouring particle problem\n",
    "- if the speed advantage is worth the effort is *in the eye of the beholder* and distinctly depends on your (or: the programmer's) abilities to write fast C-code\n",
    "- if you are neither highly-skilled nor highly-interested in programming, this solution is probably not for you ..."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Optimisation 5: Writing larger code sections in C++ - *SWIG*, *CMake* and *Python*\n",
    "\n",
    "- we saw that C-interface to provide us with the performance we lack in Python\n",
    "- various JIT-compilers provide *C-bindings* during runtime\n",
    "- *Just-in-Time* compilation has its limits:\n",
    "  - compiling external code takes time itself\n",
    "  - external dependencies and parallelisation hard to do in JIT\n",
    "  - open door for: dependency errors, pointer errors, lack of testing, undiscovered bottlenecks ...\n",
    "- larger projects do not use JIT-compiled binaries, then use pre-compiled binaries\n",
    "  - ever asked yourself why NumPy / SciPy is so fast ? those are pre-compiled c-bindings to high-speed linear algebra libraries via *pre-compiled binaries*\n",
    "  - allows full customisation and control\n",
    "  - allows also full C++ as base language (not only strict-C)\n",
    "  - well embedded in established build & distribution systems: Autotools, CMake, etc.\n",
    "- most accessible starting point: SWIG & CMake\n",
    "- we follow up with an example guideline\n",
    "\n",
    "### 1. Write your C-code\n",
    "\n",
    "Header *(knn_swig.hpp)*:\n",
    "```\n",
    "#ifndef __KNN_SWIG_HPP\n",
    "#define __KNN_SWIG_HPP\n",
    "\n",
    "#include <math.h>\n",
    "#include <malloc.h>\n",
    "#include <stdio.h>\n",
    "#include <string.h>\n",
    "\n",
    "unsigned long get_index_columnorder(int row, int rows, int column, int columns);\n",
    "unsigned long get_index_roworder(int row, int rows, int column, int columns);\n",
    "void kNN_particles_swig(float* particles, int rows, int columns, int* kNN_indices, double* kNN_distances, float r, int k);\n",
    "\n",
    "#endif\n",
    "#endif // __KNN_SWIG_HPP\n",
    "```\n",
    "\n",
    "Code *(knn_swig.cpp)*:\n",
    "```\n",
    "#include \"knn_swig.hpp\"\n",
    "\n",
    "unsigned long get_index_columnorder(int row, int rows, int column, int columns) {\n",
    "    return (row*columns)+column;\n",
    "}\n",
    "\n",
    "unsigned long get_index_roworder(int row, int rows, int column, int columns) {\n",
    "    return (column*rows)+row;\n",
    "}\n",
    "\n",
    "void kNN_particles_swig(float* particles, int rows, int columns, int* kNN_indices, double* kNN_distances, float r, int k) {\n",
    "    int N = rows;\n",
    "    double dx, dy, dv_len_sqr, m, l;\n",
    "    double* distance_matrix = (double*)malloc(sizeof(double)*rows*rows);\n",
    "    memset(distance_matrix, (double)r, sizeof(double)*rows*rows);\n",
    "    for(int i=0; i<N; i++) {\n",
    "        for(int j=i; j<N; j++) {\n",
    "            if(i==j) {\n",
    "                distance_matrix[get_index_columnorder(i,N,j,N)] = 0.0;\n",
    "                continue;\n",
    "            }\n",
    "            dx = particles[get_index_columnorder(i, N, 0, 3)]-particles[get_index_columnorder(j, N, 0, 3)];\n",
    "            dy = particles[get_index_columnorder(i, N, 1, 3)]-particles[get_index_columnorder(j, N, 1, 3)];\n",
    "            dv_len_sqr = dx*dx+dy*dy;\n",
    "            distance_matrix[get_index_columnorder(i,N,j,N)] = dv_len_sqr;\n",
    "            distance_matrix[get_index_columnorder(j,N,i,N)] = dv_len_sqr;\n",
    "        }\n",
    "    }\n",
    "\n",
    "    for(int i=0; i<N; i++) {\n",
    "        for(int j=i; j<N; j++) {\n",
    "            if(i==j) {\n",
    "                continue;\n",
    "            }\n",
    "            m = 0;\n",
    "            while((m<k) && ((kNN_indices[get_index_columnorder(i, N, m, k)] < 0) || (kNN_distances[get_index_columnorder(i, N, m, k)] <= distance_matrix[get_index_columnorder(i, N, j, N)]))) {\n",
    "                m++;\n",
    "            }\n",
    "            if(m >= k) {\n",
    "                continue;\n",
    "            }\n",
    "            l = k-1;\n",
    "            while(l>m) {\n",
    "                kNN_indices[get_index_columnorder(i, N, l, k)] = kNN_indices[get_index_columnorder(i, N, l-1, k)];\n",
    "                kNN_distances[get_index_columnorder(i, N, l, k)] = kNN_distances[get_index_columnorder(i, N, l-1, k)];\n",
    "            }\n",
    "            kNN_indices[get_index_columnorder(i, N, m, k)] = j;\n",
    "            kNN_distances[get_index_columnorder(i, N, m, k)] = distance_matrix[get_index_columnorder(i, N, j, N)];\n",
    "        }\n",
    "    }\n",
    "\n",
    "\n",
    "    free(distance_matrix);\n",
    "    return;\n",
    "}\n",
    "```\n",
    "\n",
    "### 2. Write your CMakeFiles and folder structure for your C-code project\n",
    "\n",
    "```\n",
    "knn_cmake\n",
    "- CMake\n",
    "  - FindPython.cmake\n",
    "  - FindPython2.cmake\n",
    "  - FindPython3.cmake\n",
    "  - FindSWIG.cmake\n",
    "  - FindNumpy.cmake\n",
    "- include\n",
    "  - knn_swig.hpp\n",
    "- src\n",
    "  - knn_swig.cpp\n",
    "- wrapping\n",
    "  - python\n",
    "    - CMakeLists.txt\n",
    "    - knn_swig.i\n",
    "  - CMakeLists.txt\n",
    "- CMakeLists.txt\n",
    "```\n",
    "\n",
    "- How do I write CMake code ? That's a 3-month course in itself ...\n",
    "- show example\n",
    "\n",
    "### 3. Write SWIG-Python interface file\n",
    "\n",
    "Interface *(knn_swig.i)*:\n",
    "```\n",
    "%module knn_swig\n",
    "\n",
    "// Add necessary symbols to generated header\n",
    "%{\n",
    "#define SWIG_FILE_WITH_INIT\n",
    "#include <Python.h>\n",
    "#include <knn_swig.hpp>\n",
    "%}\n",
    "\n",
    "%include \"stdint.i\"\n",
    "%include \"std_string.i\"\n",
    "%include \"typemap.i\"\n",
    "%include \"numpy.i\"\n",
    "\n",
    "// Process symbols in header\n",
    "%include \"knn_swig.hpp\"\n",
    "\n",
    "%unignore \"\"; // unignore all\n",
    "```\n",
    "\n",
    "### 4. Run CMake, compile the library\n",
    "\n",
    "```\n",
    "cd knn_cmake\n",
    "mkdir build && cd build\n",
    "ccmake ..\n",
    "make\n",
    "make install\n",
    "```\n",
    "\n",
    "### 5. Import the generated wrapper and use the function\n",
    "\n",
    "in your python code:\n",
    "```\n",
    "from knn_swig import *\n",
    "kNN_particles_ctypes(particles, rows, columns, kNN_indices, kNN_distances, r, k)\n",
    "```\n",
    "\n",
    "### Why do I not have a running example ?\n",
    "\n",
    "- coding the whole CMake structure takes half a week, even for me, even for this simple example\n",
    "- too much time for a PFL\n",
    "- lots of effort (perhaps too much) in small, temporary projects or few simulation scenarios\n",
    "- if you wanna build a fast, efficient and large library for long-term, the time investment does pay off\n",
    "- side-note: As I am mainly a computer scientist involved with speed, graphics, visualisation and the like, using *SWIG*, *CMake* and *C++* is my starndard *modus operandus*\n",
    "  - gives full control\n",
    "  - provides the fastest code (because it really runs actually C++ code, you just don't see it as a user)\n",
    "  - if facilitates interfaces to the whole software library database of the past 65 years\n",
    "  - it has virtually no limitations - APART from having very long development times\n",
    "- development time with C++, SWIG, CMake and Python\n",
    "  - it is long - really, really long \n",
    "    - if you need to get something to show in a week, this 'toolchain' is not your choice\n",
    "    - if you use this toolchain, requests for short-term changes are 'neyed' by-default - on purpose and for good reasons\n",
    "    - this style of coding requires long-term planning, vision and dedication"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Conclusion - Comparison of different computational modes and C-bindings\n",
    "\n",
    "Lastly, we collect the measurements again from the different performance optimisations to gain a holistic view on the benchmarking and the achieve speed-ups."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Advection - mean runtime and standard variance:                  7.6090 sec. (1.319119 sec)\n",
      "==== kNN runtimes - implementation comparison ====\n",
      "k-nearest neighbour search (NxN search space) - plain Python:    626.3603 sec.\n",
      "k-nearest neighbour search (NxN search space) - NumPy:           12.8126 sec.\n",
      "k-nearest neighbour search (NxN search space) - SciPy:           5.8021 sec.\n",
      "k-nearest neighbour search (NxN search space) - SciPy (kD-Tree): 0.8666 sec.\n",
      "k-nearest neighbour search (NxN search space) - Numba:           14.5471 sec.\n",
      "k-nearest neighbour search (NxN search space) - ctypes:          4.0169 sec.\n",
      "k-nearest neighbour search (NxN search space) - SciPy (2k pts.): 29.2809 sec.\n",
      "k-nearest neighbour search (NxN search space) - Numba (2k pts.): 146.9952 sec.\n",
      "==== kNN workload, relative to overall simulation - implementation comparison ====\n",
      "Workload percentage of kNN of total runtime - plain Python:    99.2236 \n",
      "Workload percentage of kNN of total runtime - NumPy:           58.4752\n",
      "Workload percentage of kNN of total runtime - SciPy:           42.7652\n",
      "Workload percentage of kNN of total runtime - SciPy (kD-Tree): 10.4792\n",
      "Workload percentage of kNN of total runtime - Numba:           64.1071\n",
      "Workload percentage of kNN of total runtime - ctypes:          32.5049\n",
      "==== Speed-Up factors - unitless scale factors - relative to 'plain Python' implementation ====\n",
      "kNN - speed-up - NumPy:            48.89\n",
      "kNN - speed-up - SciPy:           107.95\n",
      "kNN - speed-up - SciPy (kD-Tree): 722.78\n",
      "kNN - speed-up - Numba:            43.06\n",
      "kNN - speed-up - ctypes:          155.93\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "advect_measurements = []\n",
    "advect_measurements.append(total_advect_time_PythonOnly)\n",
    "advect_measurements.append(total_advect_time_Numpy)\n",
    "advect_measurements.append(total_advect_time_SciPy_512)\n",
    "advect_measurements.append(total_advect_time_Numba_512)\n",
    "advect_measurements.append(total_advect_time_SciPy_kd512)\n",
    "advect_measurements.append(total_advect_time_ctypes)\n",
    "advects_npa = np.array(advect_measurements)\n",
    "print(\"Advection - mean runtime and standard variance:                  {:4.4f} sec. ({:4.6f} sec)\".format(advects_npa.mean(), advects_npa.std()))\n",
    "print(\"==== kNN runtimes - implementation comparison ====\")\n",
    "print(\"k-nearest neighbour search (NxN search space) - plain Python:    {:4.4f} sec.\".format(total_knn_time_PythonOnly))\n",
    "print(\"k-nearest neighbour search (NxN search space) - NumPy:           {:4.4f} sec.\".format(total_knn_time_Numpy))\n",
    "print(\"k-nearest neighbour search (NxN search space) - SciPy:           {:4.4f} sec.\".format(total_knn_time_SciPy_512))\n",
    "print(\"k-nearest neighbour search (NxN search space) - SciPy (kD-Tree): {:4.4f} sec.\".format(total_knn_time_SciPy_kd512))\n",
    "print(\"k-nearest neighbour search (NxN search space) - Numba:           {:4.4f} sec.\".format(total_knn_time_Numba_512))\n",
    "print(\"k-nearest neighbour search (NxN search space) - ctypes:          {:4.4f} sec.\".format(total_knn_time_ctypes))\n",
    "print(\"k-nearest neighbour search (NxN search space) - SciPy (2k pts.): {:4.4f} sec.\".format(total_knn_time_SciPy_2k))\n",
    "print(\"k-nearest neighbour search (NxN search space) - Numba (2k pts.): {:4.4f} sec.\".format(total_knn_time_Numba_2k))\n",
    "print(\"==== kNN workload, relative to overall simulation - implementation comparison ====\")\n",
    "print(\"Workload percentage of kNN of total runtime - plain Python:    {:4.4f} \".format(total_knn_time_PythonOnly*100.0/total_compute_time_PythonOnly))\n",
    "print(\"Workload percentage of kNN of total runtime - NumPy:           {:4.4f}\".format(total_knn_time_Numpy*100.0/total_compute_time_Numpy))\n",
    "print(\"Workload percentage of kNN of total runtime - SciPy:           {:4.4f}\".format(total_knn_time_SciPy_512*100.0/total_compute_time_SciPy_512))\n",
    "print(\"Workload percentage of kNN of total runtime - SciPy (kD-Tree): {:4.4f}\".format(total_knn_time_SciPy_kd512*100.0/total_compute_time_SciPy_kd512))\n",
    "print(\"Workload percentage of kNN of total runtime - Numba:           {:4.4f}\".format(total_knn_time_Numba_512*100.0/total_compute_time_Numba_512))\n",
    "print(\"Workload percentage of kNN of total runtime - ctypes:          {:4.4f}\".format(total_knn_time_ctypes*100.0/total_compute_time_ctypes))\n",
    "print(\"==== Speed-Up factors - unitless scale factors - relative to 'plain Python' implementation ====\")\n",
    "print(\"kNN - speed-up - NumPy:           {:6.2f}\".format(total_knn_time_PythonOnly / total_knn_time_Numpy))\n",
    "print(\"kNN - speed-up - SciPy:           {:6.2f}\".format(total_knn_time_PythonOnly / total_knn_time_SciPy_512))\n",
    "print(\"kNN - speed-up - SciPy (kD-Tree): {:6.2f}\".format(total_knn_time_PythonOnly / total_knn_time_SciPy_kd512))\n",
    "print(\"kNN - speed-up - Numba:           {:6.2f}\".format(total_knn_time_PythonOnly / total_knn_time_Numba_512))\n",
    "print(\"kNN - speed-up - ctypes:          {:6.2f}\".format(total_knn_time_PythonOnly / total_knn_time_ctypes))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can conclude the following statements, when it comes to performance:\n",
    "- Coding compute-intensive functions in plain Python is *extremely inefficient* use of computational resources - it's very slow\n",
    "- Significant speed-ups can already be achieved with little effort by cleverly glueing one's physics-problem into matrix-like operations, using **NumPy** and **SciPy**\n",
    "- *SciPy*'s functions are nice, but \n",
    "  - (a) one needs to read up what those individual algorithms and functions do, to see if they apply to one's own scenarion\n",
    "  - (b) the functions, because they are tied to linear algebra matrix operations, can be very slow for large problem that don't fit into dense-matrix solvers\n",
    "- **Numba** is a very recent, very modern and quite easy way to transform one's original, simplistic Python-functions into super-fast C-functions with comparably little effort\n",
    "- you might as 'comparably to what': comparably to **ctypes**, which was the standard for JIT-compilation into C-code from the time before **Numba**; have a look into those helper-functions for the *ctypes* implementation to get an idea how difficult JIT-compilation was before ...\n",
    "- If you are building a long-lasting, large project that require a large amount of high-density computing and C-operations, then you need to familiarise with *pre-compiled C/C++ libraries* and the tools required to generate them\n",
    "  - **CMake**: the most widely-used, most user-friendly, but also most-compilcated-to-learn build system on the planet ...\n",
    "  - **Swig**: a versatile mark-up language to generate pre-compiled wrappers from C/C++ into languages such as Go, Python, Java, Perl and many more\n",
    "  - actual _**C**_ and **_C++_**\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}